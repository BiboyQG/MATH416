\documentclass{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{array}
\usepackage{fancyhdr}
\usepackage{amssymb}
\usepackage[shortlabels]{enumitem}

\DeclareMathOperator{\R}{\mathbb R}

\pagestyle{fancy}
\fancyhead[L]{Banghao Chi}
\fancyhead[C]{Homework 7}
\fancyhead[R]{10th Apr}

\fancyfoot[C]{\thepage}

\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0.5pt}

\begin{document}

\section*{Exercise 1}
Let $M$ be a square matrix of the form $\begin{pmatrix} A & B \\ 0 & I_n \end{pmatrix}$, for some matrix $A \in \mathcal{M}_{k\times k}(\mathbb{R})$, $B \in \mathcal{M}_{k\times n}$ and the identity matrix $I_n$. Using induction on $n$, prove that
\[\det(M) = \det(A).\]

\textbf{Solution:} \\

Base Case: $n = 1$

For $n = 1$, we have:
$$M_1 = \begin{pmatrix} A & B_1 \\ 0 & 1 \end{pmatrix}$$

By theorem of upper triangular matrices, we have:
$$\det(M_1) = \det(A) \cdot \det(1) = \det(A) \cdot 1 = \det(A)$$

Inductive Step:

Assume that for some $n = m$, we have:
$$\det(M_m) = \det\begin{pmatrix} A & B_m \\ 0 & I_m \end{pmatrix} = \det(A)$$

For $n = m+1$, split $B_{m+1}$ as $[B_m \; b_{m+1}]$. Similarly, split $I_{m+1}$ as:
$$I_{m+1} = \begin{pmatrix} I_m & 0 \\ 0 & 1 \end{pmatrix}$$

Therefore, we have:
$$M_{m+1} = \begin{pmatrix} A & B_m & b_{m+1} \\ 0 & I_m & 0 \\ 0 & 0 & 1 \end{pmatrix}$$

Using cofactor expansion along the last row:
\begin{align*}
\det(M_{m+1}) &= (-1)^{(k+m+1)+(k+m+1)} \cdot 1 \cdot \det(\tilde{M}_{m+1, m+1}) \\
&= \det(\tilde{M}_{m+1, m+1}) \\
&= \det\begin{pmatrix} A & B_m \\ 0 & I_m \end{pmatrix} \\
&= \det(A)
\end{align*}

Therefore, by the principle of mathematical induction, for any $n \geq 1$, the determinant of $M = \begin{pmatrix} A & B \\ 0 & I_n \end{pmatrix}$ equals $\det(A)$.

\newpage

\section*{Exercise 2}
For each of the following linear operators $T$ on a vector space $V$ and ordered bases $\beta$, compute $[T]_\beta$, and determine whether $\beta$ is a basis consisting of eigenvectors of $T$.

\begin{enumerate}
    \item[(a)] $V = \mathbb{R}^2$, $T(a,b) = (10a - 6b, 17a - 10b)$ and $\beta = \{(1,2),(2,3)\}$.
    \item[(b)] $V = \mathbb{R}^3$, $T(a,b,c) = (3a + 2b - 2c, -4a - 3b + 2c, -c)$ and $\beta = \{(0,1,1),(1,-1,0),(1,0,2)\}$.
\end{enumerate}

\textbf{Solution:} \\

(a) Let $v_1 = (1,2)$ and $v_2 = (2,3)$. \\

For $v_1 = (1,2)$:
\begin{align*}
    T(v_1) &= T(1,2) \\
    &= (10 \cdot 1 - 6 \cdot 2, 17 \cdot 1 - 10 \cdot 2) \\
    &= (10 - 12, 17 - 20) \\
    &= (-2, -3) \\
    &= -v_2
\end{align*}

For $v_2 = (2,3)$:
\begin{align*}
    T(v_2) &= T(2,3) \\
    &= (10 \cdot 2 - 6 \cdot 3, 17 \cdot 2 - 10 \cdot 3) \\
    &= (20 - 18, 34 - 30) \\
    &= (2, 4) \\
    &= 2v_1
\end{align*}

Therefore, the matrix $[T]_\beta$ is:
$[T]_\beta = \begin{pmatrix} 0 & 2 \\ -1 & 0 \end{pmatrix}$

For $v_1$: $T(v_1) = -v_2 \neq \lambda v_1$ for any $\lambda$ \\

For $v_2$: $T(v_2) = 2v_1 \neq \lambda v_2$ for any $\lambda$ \\

Therefore, $\beta$ is not a basis consisting of eigenvectors of $T$. \\

(b) Let $v_1 = (0,1,1)$, $v_2 = (1,-1,0)$, and $v_3 = (1,0,2)$. \\

For $v_1 = (0,1,1)$:
\begin{align*}
    T(v_1) &= T(0,1,1) \\
    &= (3 \cdot 0 + 2 \cdot 1 - 2 \cdot 1, -4 \cdot 0 - 3 \cdot 1 + 2 \cdot 1, -1 \cdot 1) \\
    &= (0, -1, -1) \\
    &= -v_1
\end{align*}

For $v_2 = (1,-1,0)$:
\begin{align*}
    T(v_2) &= T(1,-1,0) \\
    &= (3 \cdot 1 + 2 \cdot (-1) - 2 \cdot 0, -4 \cdot 1 - 3 \cdot (-1) + 2 \cdot 0, -1 \cdot 0) \\
    &= (1, -1, 0) \\
    &= v_2
\end{align*}

For $v_3 = (1,0,2)$:
\begin{align*}
    T(v_3) &= T(1,0,2) \\
    &= (3 \cdot 1 + 2 \cdot 0 - 2 \cdot 2, -4 \cdot 1 - 3 \cdot 0 + 2 \cdot 2, -1 \cdot 2) \\
    &= (-1, 0, -2) \\
    &= -v_3
\end{align*}

Therefore, the matrix $[T]_\beta$ is:
$[T]_\beta = \begin{pmatrix} -1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & -1 \end{pmatrix}$

For $v_1$: $T(v_1) = -v_1$, so $v_1$ is an eigenvector with eigenvalue $\lambda_1 = -1$ \\

For $v_2$: $T(v_2) = v_2$, so $v_2$ is an eigenvector with eigenvalue $\lambda_2 = 1$ \\

For $v_3$: $T(v_3) = -v_3$, so $v_3$ is an eigenvector with eigenvalue $\lambda_3 = -1$ \\

Therefore, $\beta$ is a basis consisting of eigenvectors of $T$.

\newpage

\section*{Exercise 3}
Let $A = \begin{pmatrix} 1 & 2 \\ 3 & 2 \end{pmatrix} \in \mathcal{M}_{2\times 2}(\mathbb{R})$.

\begin{enumerate}
    \item[(a)] Determine all the eigenvalues of $A$.

    \item[(b)] For each eigenvalue $\lambda$ of $A$, find the set of eigenvectors corresponding to $\lambda$.

    \item[(c)] If possible, find a basis for $\mathbb{R}^2$ consisting of eigenvectors of $A$.

    \item[(d)] If successful in finding such a basis, determine an invertible matrix $Q$ and a diagonal matrix $D$ such that $Q^{-1}AQ = D$.
\end{enumerate}

\textbf{Solution:} \\

(a)
\begin{align*}
\det(A - \lambda I) &= 0\\
\det\begin{pmatrix} 1-\lambda & 2 \\ 3 & 2-\lambda \end{pmatrix} &= 0\\
(1-\lambda)(2-\lambda) - 2 \cdot 3 &= 0\\
\lambda^2 - 3\lambda - 4 &= 0
\end{align*}

Therefore, $\lambda_1 = 4$ and $\lambda_2 = -1$ are the eigenvalues of $A$. \\

(b)
For $\lambda_1 = 4$:
\begin{align*}
(A - 4I)v &= 0\\
\begin{pmatrix} -3 & 2 \\ 3 & -2 \end{pmatrix}\begin{pmatrix} x \\ y \end{pmatrix} &= \begin{pmatrix} 0 \\ 0 \end{pmatrix}
\end{align*}

Therefore, the set of all eigenvectors corresponding to $\lambda_1 = 4$ is:
$\{t\begin{pmatrix} 2 \\ 3 \end{pmatrix} : t \in \mathbb{R}, t \neq 0\}$ \\

For $\lambda_2 = -1$:
\begin{align*}
(A - (-1)I)v &= 0\\
\begin{pmatrix} 2 & 2 \\ 3 & 3 \end{pmatrix}\begin{pmatrix} x \\ y \end{pmatrix} &= \begin{pmatrix} 0 \\ 0 \end{pmatrix}
\end{align*}

Therefore, the set of all eigenvectors corresponding to $\lambda_2 = -1$ is:
$\{t\begin{pmatrix} 1 \\ -1 \end{pmatrix} : t \in \mathbb{R}, t \neq 0\}$ \\

(c) If possible, find a basis for $\mathbb{R}^2$ consisting of eigenvectors of $A$.

We have two linearly independent eigenvectors:
$v_1 = \begin{pmatrix} 2 \\ 3 \end{pmatrix}$ corresponding to $\lambda_1 = 4$
$v_2 = \begin{pmatrix} 1 \\ -1 \end{pmatrix}$ corresponding to $\lambda_2 = -1$

\begin{align*}
\det\begin{pmatrix} 2 & 1 \\ 3 & -1 \end{pmatrix} = 2(-1) - 1(3) = -2 - 3 = -5 \neq 0
\end{align*}

Since they're linearly independent, they form a basis for $\mathbb{R}^2$. \\

(d) If successful in finding such a basis, determine an invertible matrix $Q$ and a diagonal matrix $D$ such that $Q^{-1}AQ = D$.

\begin{align*}
Q = \begin{pmatrix} 2 & 1 \\ 3 & -1 \end{pmatrix}
\end{align*}

\begin{align*}
D = \begin{pmatrix} 4 & 0 \\ 0 & -1 \end{pmatrix}
\end{align*}

\newpage

\section*{Exercise 4}
For each linear operator $T$ on $V$, find the eigenvalues of $T$ and an ordered basis $\beta$ for $V$ such that $[T]_\beta$ is a diagonal matrix.

\begin{enumerate}
    \item[(a)] $V = \mathbb{R}^3$ and $T(a,b,c) = (7a - 4b + 10c, 4a - 3b + 8c, -2a + b - 2c)$.

    \item[(b)] $V = \mathcal{M}_{2\times 2}(\mathbb{R})$ and $T\begin{pmatrix} a & b \\ c & d \end{pmatrix} = \begin{pmatrix} d & b \\ c & a \end{pmatrix}$.
\end{enumerate}

\textbf{Solution:} \\

(a) $V = \mathbb{R}^3$ and $T(a,b,c) = (7a - 4b + 10c, 4a - 3b + 8c, -2a + b - 2c)$.
\begin{align*}
T(e_1) &= T(1,0,0) = (7, 4, -2) \\
T(e_2) &= T(0,1,0) = (-4, -3, 1) \\
T(e_3) &= T(0,0,1) = (10, 8, -2)
\end{align*}

So the matrix representation is:
$[T] = \begin{pmatrix} 7 & -4 & 10 \\ 4 & -3 & 8 \\ -2 & 1 & -2 \end{pmatrix}$

\begin{align*}
    \det([T] - \lambda I) &= 0\\
    \det\begin{pmatrix} 7-\lambda & -4 & 10 \\ 4 & -3-\lambda & 8 \\ -2 & 1 & -2-\lambda \end{pmatrix} &= 0\\
    -\lambda^3 + 2\lambda^2 + \lambda - 2 &= 0
\end{align*}

Therefore, the eigenvalues are $\lambda_1 = -1$, $\lambda_2 = 1$, and $\lambda_3 = 2$.

For $\lambda_1 = -1$, we solve $(T + I)v = 0$:
$\begin{pmatrix} 8 & -4 & 10 \\ 4 & -2 & 8 \\ -2 & 1 & -1 \end{pmatrix} \begin{pmatrix} a \\ b \\ c \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix}$

This gives the eigenvector $v_1 = (1/2, 1, 0)$.

For $\lambda_2 = 1$, we solve $(T - I)v = 0$:
$\begin{pmatrix} 6 & -4 & 10 \\ 4 & -4 & 8 \\ -2 & 1 & -3 \end{pmatrix} \begin{pmatrix} a \\ b \\ c \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix}$

This gives the eigenvector $v_2 = (-1, 1, 1)$.

For $\lambda_3 = 2$, we solve $(T - 2I)v = 0$:
$\begin{pmatrix} 5 & -4 & 10 \\ 4 & -5 & 8 \\ -2 & 1 & -4 \end{pmatrix} \begin{pmatrix} a \\ b \\ c \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix}$

This gives the eigenvector $v_3 = (-2, 0, 1)$. \\

Therefore, an ordered basis $\beta = \{v_1, v_2, v_3\}$ gives the diagonal matrix:
$[T]_\beta = \begin{pmatrix} -1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 2 \end{pmatrix}$

(b) Let
\[
E_{11} 
= \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix}, 
\quad
E_{12} 
= \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix},
\quad
E_{21} 
= \begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix},
\quad
E_{22} 
= \begin{pmatrix} 0 & 0 \\ 0 & 1 \end{pmatrix}.
\]

We have:
\[
T(E_{11})
= \begin{pmatrix} 0 & 0 \\ 0 & 1 \end{pmatrix}
= E_{22}, 
\quad
T(E_{12})
= \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix}
= E_{12},
\]
\[
T(E_{21})
= \begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix}
= E_{21},
\quad
T(E_{22})
= \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix}
= E_{11}.
\]

Thus $E_{12}$ and $E_{21}$ are eigenvectors with eigenvalue $1$.
\[
T(E_{11} + E_{22})
= T(E_{11}) + T(E_{22})
= E_{22} + E_{11}
= E_{11} + E_{22},
\]

So $E_{11} + E_{22}$ is an eigenvector of eigenvalue $1$.
\[
T(E_{11} - E_{22})
= T(E_{11}) - T(E_{22})
= E_{22} - E_{11}
= -(E_{11} - E_{22}),
\]

So $E_{11} - E_{22}$ is an eigenvector of eigenvalue $-1$. \\

Therefore, the basis of eigenvectors is:
\[
\beta = 
\Bigl\{
E_{12}, \, E_{21}, \, (E_{11} + E_{22}), \, (E_{11} - E_{22})
\Bigr\}.
\]

With respect to this basis, $T$ is diagonal, and its matrix is:
\[
[T]_{\beta}
=
\begin{pmatrix}
1 & 0 & 0 & 0 \\[4pt]
0 & 1 & 0 & 0 \\[4pt]
0 & 0 & 1 & 0 \\[4pt]
0 & 0 & 0 & -1
\end{pmatrix}
\]

\newpage

\section*{Exercise 5}
Let $T$ be a linear operator on a finite-dimensional vector space $V$.

\begin{enumerate}
    \item[(a)] Show that $T$ is invertible if and only if $0$ is not an eigenvalue of $T$.
    \item[(b)] If $T$ is invertible, show that $\lambda^{-1}$ is an eigenvalue of $T^{-1}$ if and only if $\lambda$ is an eigenvalue of $T$.
\end{enumerate}

\textbf{Solution:} \\

(a) ($\Rightarrow$) Suppose $T$ is invertible and assume, for contradiction, that $0$ is an eigenvalue of $T$. \\

Then there exists a nonzero vector $v \in V$ such that $T(v) = 0v = 0$. Applying $T^{-1}$ to both sides: $T^{-1}(T(v)) = T^{-1}(0)$. This gives $v = 0$ (since $T^{-1}(0) = 0$). \\

This contradicts the fact that $v$ is nonzero. Therefore, $0$ cannot be an eigenvalue of $T$. \\

($\Leftarrow$) Suppose $0$ is not an eigenvalue of $T$. \\

$T$ is invertible $\Leftrightarrow$ $T$ is bijective. \\

For injectivity: Suppose $T(v) = T(w)$ for vectors $v,w \in V$. \\

Then $T(v-w) = 0$ by linearity. \\

Since $0$ is not an eigenvalue, the only vector mapped to $0$ is the zero vector. \\

So $v-w = 0 \Rightarrow v = w$, proving $T$ is injective. \\

For a linear transformation on a finite-dimensional vector space, injectivity implies surjectivity by the rank-nullity theorem:
\begin{align*}
\dim(\text{Null}(T)) + \dim(\text{Range}(T)) &= \dim(V)
\end{align*}

Since $T$ is injective, $\dim(\text{Null}(T)) = 0$, thus $\dim(\text{Range}(T)) = \dim(V)$, which means $T$ is surjective. \\

Therefore, $T$ is bijective, hence invertible. \\

(b) ($\Rightarrow$) Suppose $\lambda$ is an eigenvalue of $T$ with eigenvector $v \neq 0$. \\

Then $T(v) = \lambda v$. \\

Applying $T^{-1}$ to both sides: $T^{-1}(T(v)) = T^{-1}(\lambda v)$. \\

This gives $v = \lambda T^{-1}(v)$ by linearity. \\

So $T^{-1}(v) = \frac{1}{\lambda}v = \lambda^{-1}v$. \\

So $\lambda^{-1}$ is an eigenvalue of $T^{-1}$ with the same eigenvector $v$. \\

($\Leftarrow$) Suppose $\lambda^{-1}$ is an eigenvalue of $T^{-1}$ with eigenvector $v \neq 0$. \\

Then $T^{-1}(v) = \lambda^{-1}v$. \\

Applying $T$ to both sides: $T(T^{-1}(v)) = T(\lambda^{-1}v)$. \\

This gives $v = \lambda^{-1}T(v)$ by linearity. \\

So $T(v) = \lambda v$. \\

Therefore, $\lambda$ is an eigenvalue of $T$ with the same eigenvector $v$.

\newpage

\section*{Exercise 6}
Suppose $T : V \rightarrow V$ is a linear operator on a finite-dimensional vector space $V$. Suppose $v \in V$ is an eigenvector of $T$ with eigenvalue $\lambda$. As usual, $T^m : V \rightarrow V$ denotes composition of $T$ with itself $m$ times. Prove that $v$ is also an eigenvector for $T^m$ and give a formula for the corresponding eigenvalue. \\

\textbf{Solution:} \\

Prove by induction. \\

Base case ($m = 1$): We have $T^1(v) = T(v) = \lambda v = \lambda^1 v$, so the statement holds. \\

Inductive step: Assume that for some positive integer $k$, $v$ is an eigenvector of $T^k$ with eigenvalue $\lambda^k$, meaning:
\begin{align*}
T^k(v) = \lambda^k v
\end{align*}

For $T^{k+1}(v)$:
\begin{align*}
T^{k+1}(v) &= T(T^k(v))\\
&= T(\lambda^k v)\\
&= \lambda^k T(v)\\
&= \lambda^k (\lambda v)\\
&= \lambda^{k+1} v
\end{align*}

Therefore, $v$ is an eigenvector of $T^{k+1}$ with eigenvalue $\lambda^{k+1}$. \\

By the principle of mathematical induction, $v$ is an eigenvector of $T^m$ with eigenvalue $\lambda^m$ for all positive integers $m$.

\end{document}