\documentclass{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{array}
\usepackage{fancyhdr}
\usepackage{amssymb}
\usepackage[shortlabels]{enumitem}

\DeclareMathOperator{\R}{\mathbb R}

\pagestyle{fancy}
\fancyhead[L]{Banghao Chi}
\fancyhead[C]{Homework 7}
\fancyhead[R]{14th Apr}

\fancyfoot[C]{\thepage}

\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0.5pt}

\begin{document}

\section*{Exercise 1}
Answer the following questions.

\begin{itemize}
    \item[(a)] Check if $A = \begin{pmatrix} 0 & 0 & 1 \\ 1 & 0 & -1 \\ 0 & 1 & 1 \end{pmatrix}$ is diagonalizable. If yes, find an invertible matrix $Q$ and a diagonal matrix $D$ such that $Q^{-1}AQ = D$.
    \item[(b)] Do the same as (a) for $A = \begin{pmatrix} 3 & 1 & 1 \\ 2 & 4 & 2 \\ -1 & -1 & 1 \end{pmatrix}$.
    \item[(c)] Check if the linear operator $T$ on $\mathcal{P}_3(\mathbb{R})$ given by $T(f(x)) = f'(x) + f''(x)$ is diagonalizable. If yes, find a basis $\gamma$ such that $[T]_{\gamma}$ is a diagonal matrix.
    \item[(d)] Do the same as (c) for $T(f(x)) = f(0) + f(1)(x + x^2)$ on $\mathcal{P}_2(\mathbb{R})$.
\end{itemize}

\textbf{Solution:} \\

\begin{itemize}
    \item[(a)]
    The characteristic polynomial of \(A\) is:
\[
\det(A - \lambda I)
= \det\!
\begin{pmatrix}
-\lambda & 0 & 1\\
1 & -\lambda & -1\\
0 & 1 & 1-\lambda
\end{pmatrix} = (\lambda - 1)\,\bigl(\lambda^2 + 1\bigr)
\]
Hence the eigenvalues are
\[
\lambda = 1,\quad \lambda = i,\quad \lambda = -i.
\]
\[
A - I = 
\begin{pmatrix}
-1 & 0 & 1\\
1 & -1 & -1\\
0 & 1 & 0
\end{pmatrix},
\quad
A - iI =
\begin{pmatrix}
-\,i & 0 & 1\\
1 & -\,i & -1\\
0 & 1 & 1 - i
\end{pmatrix},
\quad
A + iI =
\begin{pmatrix}
\,i & 0 & 1\\
1 & \,i & -1\\
0 & 1 & 1 + i
\end{pmatrix}.
\]

1) For \(\lambda = 1\), we solve \((A - I)v = 0\). 
\[
\begin{pmatrix}
-1 & 0 & 1\\
1 & -1 & -1\\
0 & 1 & 0
\end{pmatrix}
\begin{pmatrix}
x \\ y \\ z
\end{pmatrix}
= 
\begin{pmatrix}
0 \\ 0 \\ 0
\end{pmatrix}.
\]
We get $v_1 = \begin{pmatrix}1 \\ 0 \\ 1\end{pmatrix}.$

2) For \(\lambda = i\), we solve \((A - iI)v = 0\).
\[
\begin{pmatrix}
-i & 0 & 1\\
1 & -i & -1\\
0 & 1 & 1-i
\end{pmatrix}
\begin{pmatrix}
x \\ y \\ z
\end{pmatrix}
= 
\begin{pmatrix}
0 \\ 0 \\ 0
\end{pmatrix}.
\]
We get $v_2 = \begin{pmatrix}-i \\ -1+i \\ 1\end{pmatrix}$.

3) For \(\lambda = -i\), we solve \((A + iI)v = 0\).
\[
\begin{pmatrix}
i & 0 & 1\\
1 & i & -1\\
0 & 1 & 1+i
\end{pmatrix}
\begin{pmatrix}
x \\ y \\ z
\end{pmatrix}
= 
\begin{pmatrix}
0 \\ 0 \\ 0
\end{pmatrix}.
\]

We get $v_3 = \begin{pmatrix}i \\ -1-i \\ 1\end{pmatrix}$.

Therefore, $Q = \begin{pmatrix}1 & -i & i \\ 0 & -1+i & -1-i \\ 1 & 1 & 1\end{pmatrix}$ and $D = \begin{pmatrix}1 & 0 & 0 \\ 0 & i & 0 \\ 0 & 0 & -i\end{pmatrix}$. A is diagonalizable over complex numbers, with eigenvalues $1, i, -i$.

    \item[(b)]
    The characteristic polynomial of
\[
\lambda^3 - 8\lambda^2 + 20\lambda - 16,
\]
which factors as
\[
(\lambda - 2)^2 (\lambda - 4).
\]
Therefore the eigenvalues are \(2\) (with algebraic multiplicity \(2\)) and \(4\).

For \(\lambda = 2\), a basis of the eigenspace is:
\[
v_1 = \begin{pmatrix} -1 \\[6pt] 1 \\[6pt] 0 \end{pmatrix},
\quad
v_2 = \begin{pmatrix} -1 \\[6pt] 0 \\[6pt] 1 \end{pmatrix}.
\]
For \(\lambda = 4\), an eigenvector is
\[
v_3 = \begin{pmatrix} -1 \\[6pt] -2 \\[6pt] 1 \end{pmatrix}.
\]

Therefore:
\[
P
=
\begin{pmatrix}
-1 & -1 & -1 \\
\;\,1 & \;\,0 & -2 \\
\;\,0 & \;\,1 & \;\,1
\end{pmatrix}.
\]
And:
\[
D
=
\mathrm{diag}(2,\,2,\,4).
\]

Thus the matrix \(A\) is diagonalizable (over the real numbers) with eigenvalues \(2, 2, 4\).
    
    \item[(c)]
    For the standard basis \(\{1, x, x^2, x^3\}\), we have:
    \[
    T(1) = 0,\quad
    T(x) = 1,\quad
    T(x^2) = 2 + 2x,\quad
    T(x^3) = 3x^2 + 6x.
    \]
    Resulting in a strictly upper triangular matrix. The only eigenvalue is 0, and its eigenspace has dimension 1. Since the space has dimension 4, we cannot find 4 linearly independent eigenvectors. Therefore \(T\) is not diagonalizable.
    
    \item[(d)]
    For the standard basis \(\{1, x, x^2\}\):
    \[
    T(1) = 1 + x + x^2,\quad
    T(x) = x + x^2,\quad
    T(x^2) = x + x^2.
    \]
    The corresponding matrix is
    \[
    \begin{pmatrix}
    1 & 0 & 0\\
    1 & 1 & 1\\
    1 & 1 & 1
    \end{pmatrix}.
    \]
    The characteristic polynomial is \((\lambda - 0)(\lambda - 1)(\lambda - 2)\), giving distinct eigenvalues \(0, 1, 2\). Hence \(T\) is diagonalizable. $v_1 = \begin{pmatrix}0 \\ -1 \\ 1\end{pmatrix}, v_2 = \begin{pmatrix}-1 \\ 1 \\ 1\end{pmatrix}, v_3 = \begin{pmatrix}0 \\ 1 \\ 1\end{pmatrix}$ are eigenvectors for eigenvalues 0, 1, 2 respectively. Therefore, the basis $\gamma = \{v_1, v_2, v_3\}$ diagonalizes $T$.
    \end{itemize}

\newpage

\section*{Exercise 2}
For $A = \begin{pmatrix} 1 & 4 \\ 2 & 3 \end{pmatrix}$, find an expression for $A^n$, where $n$ is an arbitrary positive integer. \\

\textbf{Solution:} \\

If $A$ is diagonalizable, $A = PDP^{-1}$ implies $A^n = PD^nP^{-1}$. \\

The characteristic polynomial of $A$ is:
\begin{align*}
\det(A - \lambda I) &= \det\begin{pmatrix} 1-\lambda & 4 \\ 2 & 3-\lambda \end{pmatrix} \\
&= (1-\lambda)(3-\lambda) - 8 \\
&= \lambda^2 - 4\lambda - 5 \\
&= (\lambda - 5)(\lambda + 1)
\end{align*}

So $\lambda_1 = 5$ and $\lambda_2 = -1$ \\

For $\lambda_1 = 5$:
\begin{align*}
(A - 5I)v_1 &= \begin{pmatrix} -4 & 4 \\ 2 & -2 \end{pmatrix}v_1 = \vec{0}
\end{align*}

This gives $v_1 = \begin{pmatrix} 1 \\ 1 \end{pmatrix}$

For $\lambda_2 = -1$:
\begin{align*}
(A + I)v_2 &= \begin{pmatrix} 2 & 4 \\ 2 & 4 \end{pmatrix}v_2 = \vec{0}
\end{align*}

This gives $v_2 = \begin{pmatrix} -2 \\ 1 \end{pmatrix}$ \\

$P = \begin{pmatrix} 1 & -2 \\ 1 & 1 \end{pmatrix}$ \\

$P^{-1} = \frac{1}{3}\begin{pmatrix} 1 & 2 \\ -1 & 1 \end{pmatrix}$ \\

$D = \begin{pmatrix} 5 & 0 \\ 0 & -1 \end{pmatrix}$ \\

$D^n = \begin{pmatrix} 5^n & 0 \\ 0 & (-1)^n \end{pmatrix}$ \\

Therefore:
$$A^n = PD^nP^{-1}$$

\newpage

\section*{Exercise 3}
If A is a square matrix prove that $A$ and $A^t$ have the same eigenvalues. Do they have the same eigenvectors? Either prove they do, or give a counterexample. \\

\textbf{Solution:} \\

\begin{itemize}
    \item[(a)] $A$ and $A^T$ have the same eigenvalues.

    For a matrix $A$, the characteristic polynomial is:
\begin{align*}
\det(A^T - \lambda I) &= \det((A^T - \lambda I)^T) \\
&= \det(A - \lambda I^T) \\
&= \det(A - \lambda I)
\end{align*}

Since the characteristic polynomials are identical, $A$ and $A^T$ have the same eigenvalues.

    \item[(b)] $A$ and $A^T$ do not have the same eigenvectors.

    Counterexample:

Let $A = \begin{pmatrix} 1 & 1 \\ 0 & 2 \end{pmatrix}$. So $A^T = \begin{pmatrix} 1 & 0 \\ 1 & 2 \end{pmatrix}$.

The characteristic polynomial for both is $(1-\lambda)(2-\lambda) = 0$, giving eigenvalues $\lambda = 1$ and $\lambda = 2$.

For $A$ with $\lambda = 1$, we have:
\begin{align*}
(A-I)v &= \begin{pmatrix} 0 & 1 \\ 0 & 1 \end{pmatrix}\begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}
\end{align*}

This gives $v = \begin{pmatrix} 1 \\ 0 \end{pmatrix}$.

For $A^T$ with $\lambda = 1$, we have:
\begin{align*}
(A^T-I)w &= \begin{pmatrix} 0 & 0 \\ 1 & 1 \end{pmatrix}\begin{pmatrix} w_1 \\ w_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}
\end{align*}

This gives $w = \begin{pmatrix} 1 \\ -1 \end{pmatrix}$.

Similarly, for $\lambda = 2$:
\begin{itemize}
    \item $A$ has eigenvector $\begin{pmatrix} 1 \\ 1 \end{pmatrix}$
    \item $A^T$ has eigenvector $\begin{pmatrix} 0 \\ 1 \end{pmatrix}$
\end{itemize}

Therefore, while $A$ and $A^T$ always have the same eigenvalues, they generally have different eigenvectors.
\end{itemize}
\newpage

\section*{Exercise 4}
Prove that if a 1-dimensional subspace $W$ of $\mathbb{R}^n$ contains a nonzero vector with all nonnegative entries, then $W$ contains a unique probability vector. \\

\textbf{Solution:} \\

Since $W$ is 1-dimensional, every vector in $W$ is a scalar multiple of any nonzero vector in $W$. As $w$ is a nonzero vector in $W$, every vector in $W$ is of the form $\alpha w$ for some scalar $\alpha$. \\

Let $S(w) = \sum_{i=1}^n w_i$ be the sum of all entries in $w$. Since $w$ has all nonnegative entries and is nonzero, $S(w) > 0$. \\

Let $p = \frac{w}{S(w)}$. Since $w$ has all nonnegative entries, so does $p$. Moreover,
\begin{align*}
\sum_{i=1}^n p_i &= \sum_{i=1}^n \frac{w_i}{S(w)} \\
&= \frac{1}{S(w)} \sum_{i=1}^n w_i \\
&= \frac{S(w)}{S(w)} \\
&= 1
\end{align*}

Therefore, $p$ is a probability vector in $W$. \\

For uniqueness, suppose $q$ is another probability vector in $W$. Since $q \in W$, we have $q = \alpha w$ for some scalar $\alpha$. \\

Since $q$ is a probability vector, $\sum_{i=1}^n q_i = 1$, we have:
\begin{align*}
\sum_{i=1}^n q_i &= 1 \\
\sum_{i=1}^n \alpha w_i &= 1 \\
\alpha \sum_{i=1}^n w_i &= 1 \\
\alpha S(w) &= 1
\end{align*}

Solving for $\alpha$, we get $\alpha = \frac{1}{S(w)}$. Thus, $q = \frac{1}{S(w)} w = p$, proving that $p$ is the unique probability vector in $W$.

\newpage

\section*{Exercise 5}
A hospital trauma unit has determined that 30\% of its patients are ambulatory and 70\% are bedridden at the time of arrival at the hospital. A month after arrival, 60\% of the ambulatory patients have recovered, 20\% remain ambulatory, and 20\% have become bedridden. After the same amount of time, 10\% of the bedridden patients have recovered, 20\% have become ambulatory, 50\% remain bedridden, and 20\% have died. Determine the percentages of patients who have recovered, are ambulatory, are bedridden, and have died 1 month after arrival. Also determine the eventual percentages of patients of each type. \\

\textbf{Solution:} \\

Define the states:
R: Recovered
A: Ambulatory
B: Bedridden
D: Dead

Therefore, we have the following transition matrix $T$:
\begin{align*}
T = 
\begin{bmatrix}
1.0 & 0.6 & 0.1 & 0.0 \\
0.0 & 0.2 & 0.2 & 0.0 \\
0.0 & 0.2 & 0.5 & 0.0 \\
0.0 & 0.0 & 0.2 & 1.0
\end{bmatrix}
\end{align*}

The initial distribution is:
\begin{align*}
P_0 = 
\begin{bmatrix}
0 \\
0.3 \\
0.7 \\
0
\end{bmatrix}
\end{align*}

Let's calculate the distribution after one month:
\begin{align*}
P_1 &= T \cdot P_0\\
&= 
\begin{bmatrix}
1.0 & 0.6 & 0.1 & 0.0 \\
0.0 & 0.2 & 0.2 & 0.0 \\
0.0 & 0.2 & 0.5 & 0.0 \\
0.0 & 0.0 & 0.2 & 1.0
\end{bmatrix}
\begin{bmatrix}
0 \\
0.3 \\
0.7 \\
0
\end{bmatrix}\\
&= 
\begin{bmatrix}
0.25 \\
0.20 \\
0.41 \\
0.14
\end{bmatrix}
\end{align*}

Therefore, after one month:
\begin{itemize}
    \item 25\% have recovered
    \item 20\% are ambulatory
    \item 41\% are bedridden
    \item 14\% have died
\end{itemize}
\begin{align*}
\text{det}
\begin{bmatrix}
1-\lambda & 0.6 & 0.1 & 0 \\
0 & 0.2-\lambda & 0.2 & 0 \\
0 & 0.2 & 0.5-\lambda & 0 \\
0 & 0 & 0.2 & 1-\lambda
\end{bmatrix} = 0
\end{align*}

This gives us: $(1-\lambda)^2 \cdot (0.1-\lambda) \cdot (0.6-\lambda) = 0$

To find the corresponding eigenvectors:
\begin{itemize}
    \item For $\lambda = 1$: $v_1 = \begin{bmatrix} 1 \\ 0 \\ 0 \\ 0 \end{bmatrix}$ and $v_2 = \begin{bmatrix} 0 \\ 0 \\ 0 \\ 1 \end{bmatrix}$
    \item For $\lambda = 0.1$: $v_3 = \begin{bmatrix} 0.544 \\ -0.89 \\ 0.445 \\ -0.1 \end{bmatrix}$
    \item For $\lambda = 0.6$: $v_4 = \begin{bmatrix} 0.817 \\ -0.41\\ -0.817 \\ 0.41 \end{bmatrix}$
\end{itemize}

Therefore, we can form the matrices $P$ and $D$:
\begin{align*}
P &= 
\begin{bmatrix}
1 & 0 & 0.544 & 0.817 \\
0 & 0 & -0.89 & -0.41 \\
0 & 0 & 0.445 & -0.817 \\
0 & 1 & -0.1 & 0.41
\end{bmatrix} \\
D &= 
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 0.1 & 0 \\
0 & 0 & 0 & 0.6
\end{bmatrix}
\end{align*}

As $n$ approaches infinity, $D^n$ becomes:
\begin{align*}
D^n \to
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0
\end{bmatrix}
\end{align*}

Computing $T^n = PD^nP^{-1}$ as $n \to \infty$, we get:
\begin{align*}
T^\infty \approx 
\begin{bmatrix}
1 & 0.89 & 0.554 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0.11 & 0.446 & 1
\end{bmatrix}
\end{align*}

Therefore:
\begin{align*}
P_\infty &= T^\infty \cdot P_0 \\
&= 
\begin{bmatrix}
1 & 0.89 & 0.554 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0.11 & 0.446 & 1
\end{bmatrix}
\begin{bmatrix}
0 \\
0.3 \\
0.7 \\
0
\end{bmatrix} \\
&= 
\begin{bmatrix}
0.656 \\
0 \\
0 \\
0.344
\end{bmatrix}
\end{align*}

Therefore, the eventual percentages are:
\begin{itemize}
    \item 65.6\% Recovered
    \item 0\% Ambulatory
    \item 0\% Bedridden
    \item 34.4\% Dead
\end{itemize}

\newpage

\section*{Exercise 6}
A player begins a game of chance by placing a marker in box 2, marked Start. A die is rolled, and the marker is moved one square to the left if a 1 or a 2 is rolled and one square to the right if a 3, 4, 5, or 6 is rolled. This process continues until the marker lands in square 1, in which case the player wins the game, or in square 4, in which case the player loses the game. What is the probability of winning this game?

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Win & Start & & Lose \\
1 & 2 & 3 & 4 \\
\hline
\end{tabular}
\end{center}

Hint: Instead of diagonalizing the appropriate transition matrix $A$, it is easier to represent $e_2$ as a linear combination of eigenvectors of $A$ and then apply $A^n$ to the result. \\

\textbf{Solution:} \\



\end{document}